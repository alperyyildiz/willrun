

 TYPE:   CONV 
 
LAYER:
1 	---	FIL: 64 		batchnorm: False 		activation_function: [True, 'relu'] 		
2 	---	FIL: 48 		batchnorm: False 		activation_function: [True, 'relu'] 		

 TYPE:   DENSE 
 
LAYER:
1 	---	activation_function: [True, 'relu'] 		
2 	---	FIL: 32 		dropout: [True, 0.4] 		activation_function: [True, 'relu'] 		
3 	---	FIL: 4 		dropout: [False, 0] 		activation_function: [False, '-'] 		

 TYPE:   OTHERS 
 
LAYER:
1 	---	windowlength: 24 		out_size: 4 		period: 24 		lrate: 0.003 		batchsize: 16 		epoch: 201 		
